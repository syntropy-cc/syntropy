#!/bin/bash

#===============================================================================
# OUTPUT HANDLER
#===============================================================================

# Importa dependências
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" &> /dev/null && pwd)"
source "$SCRIPT_DIR/logger.sh"
source "$SCRIPT_DIR/utils.sh"

# Configuração global
if [[ -z "$DIAGNOSTIC_BASE_DIR" ]]; then
    declare -r DIAGNOSTIC_BASE_DIR="$(dirname "$SCRIPT_DIR")"
fi
declare OUTPUT_DIR=""
declare LAYER_NAME=""
declare TIMESTAMP=""
declare LOGS_DIR=""
if [[ -z "$PID" ]]; then
    declare -r PID="$$"
fi

#===============================================================================
# DIRECTORY MANAGEMENT
#===============================================================================

init_output_handler() {
    local layer="$1"
    LAYER_NAME="$layer"
    TIMESTAMP="$(date +%Y%m%d_%H%M%S)"
    
    # Cria estrutura hierárquica conforme arquitetura
    OUTPUT_DIR="$DIAGNOSTIC_BASE_DIR/outputs/$TIMESTAMP/$layer"
    CACHE_DIR="$OUTPUT_DIR/.cache"
    LOGS_DIR="$(dirname "$OUTPUT_DIR")/logs"

    # Cria estrutura de diretórios completa
    for dir in "$OUTPUT_DIR" "$CACHE_DIR" "$LOGS_DIR"; do
        if ! mkdir -p "$dir" 2>/dev/null; then
            log_warning "Failed to create directory, attempting with sudo: $dir"
            if ! sudo mkdir -p "$dir" 2>/dev/null; then
                log_error "Could not create directory: $dir"
                return 1
            fi
            sudo chown -R "$(id -u):$(id -g)" "$dir"
        fi

        # Verifica permissões de escrita
        if [[ ! -w "$dir" ]]; then
            log_error "Directory is not writable: $dir"
            return 1
        fi
    done

    log_debug "Output handler initialized for layer: $layer (Dir: $OUTPUT_DIR)"
    log_debug "Cache directory created at: $CACHE_DIR"
    return 0
}

get_output_dir() {
    echo "$OUTPUT_DIR"
}

get_logs_dir() {
    echo "$LOGS_DIR"
}

ensure_output_permissions() {
    local path="$1"
    if [[ ! -w "$(dirname "$path")" ]]; then
        sudo chown -R "$(id -u):$(id -g)" "$(dirname "$path")"
        if [[ $? -ne 0 ]]; then
            log_error "Failed to set permissions for: $path"
            return 1
        fi
    fi
    return 0
}

#===============================================================================
# FILE GENERATION
#===============================================================================

generate_summary_md() {
    local title="$1"
    local content="$2"
    local output_file="$OUTPUT_DIR/summary.md"

    ensure_output_permissions "$output_file" || return 1

    cat > "$output_file" << EOF
# $title

**Generated:** $(date -u +"%Y-%m-%dT%H:%M:%SZ")  
**Layer:** $LAYER_NAME  
**Process ID:** $PID  
**Timestamp:** $TIMESTAMP

---

$content

---

*Report generated by Syntropy Diagnostics System*
EOF

    log_debug "Generated summary.md at: $output_file"
    return 0
}

generate_results_json() {
    local content="$1"
    local output_file="$OUTPUT_DIR/results.json"
    local fallback_file="$OUTPUT_DIR/results_fallback.log"

    ensure_output_permissions "$output_file" || return 1
    ensure_output_permissions "$fallback_file" || return 1

    if ! echo "$content" | jq '.' > "$output_file" 2>/dev/null; then
        log_warning "Failed to generate JSON, using fallback format"
        echo "$content" > "$fallback_file"
        return 1
    fi

    log_debug "Generated results.json at: $output_file"
    return 0
}

copy_detailed_log() {
    local log_file="$1"
    local output_file="$OUTPUT_DIR/detailed.log"

    ensure_output_permissions "$output_file" || return 1

    if [[ -f "$log_file" ]]; then
        cp "$log_file" "$output_file" || {
            log_error "Failed to copy log file to: $output_file"
            return 1
        }
        log_debug "Copied detailed.log to: $output_file"
        return 0
    else
        log_error "Source log file not found: $log_file"
        return 1
    fi
}

#===============================================================================
# ENHANCED OUTPUT FUNCTIONS
#===============================================================================

generate_consolidated_report() {
    local layer="$1"
    local timestamp="$2"
    local duration="$3"
    local status="$4"
    local components="$5"
    
    local report_dir="$DIAGNOSTIC_BASE_DIR/outputs/$timestamp"
    local consolidated_file="$report_dir/consolidated_report.md"
    
    ensure_output_permissions "$consolidated_file" || return 1
    
    cat > "$consolidated_file" << EOF
# Consolidated Diagnostic Report

**Generated:** $(date -u +"%Y-%m-%dT%H:%M:%SZ")  
**Execution Time:** $timestamp  
**Total Duration:** ${duration}ms  
**Overall Status:** $status  

## Layer Summary

$components

## Detailed Reports

EOF

    # Adiciona links para relatórios detalhados de cada camada
    for layer_dir in "$report_dir"/*/; do
        if [[ -d "$layer_dir" ]]; then
            local layer_name
            layer_name=$(basename "$layer_dir")
            local summary_file="$layer_dir/summary.md"
            
            if [[ -f "$summary_file" ]]; then
                echo "- [$layer_name]($layer_name/summary.md)" >> "$consolidated_file"
            fi
        fi
    done
    
    cat >> "$consolidated_file" << EOF

---

*Consolidated report generated by Syntropy Diagnostics System*
EOF

    log_debug "Generated consolidated report at: $consolidated_file"
    return 0
}

generate_performance_metrics() {
    local start_time="$1"
    local end_time="$2"
    local layer="$3"
    
    local duration=$((end_time - start_time))
    local timestamp="$(date +%Y%m%d_%H%M%S)"
    
    # Calcula métricas de performance
    local cpu_usage
    cpu_usage=$(ps -p $PID -o %cpu= 2>/dev/null || echo "0")
    
    local memory_usage
    memory_usage=$(ps -p $PID -o %mem= 2>/dev/null || echo "0")
    
    # Gera arquivo de métricas
    local metrics_file="$DIAGNOSTIC_BASE_DIR/outputs/$timestamp/$layer/performance.json"
    
    ensure_output_permissions "$metrics_file" || return 1
    
    cat > "$metrics_file" << EOF
{
    "layer": "$layer",
    "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "execution": {
        "start_time": $start_time,
        "end_time": $end_time,
        "duration_ms": $duration
    },
    "resources": {
        "cpu_usage_percent": $cpu_usage,
        "memory_usage_percent": $memory_usage,
        "process_id": $PID
    },
    "performance_score": $(calculate_performance_score "$duration" "$cpu_usage" "$memory_usage")
}
EOF

    log_debug "Generated performance metrics at: $metrics_file"
    return 0
}

calculate_performance_score() {
    local duration="$1"
    local cpu_usage="$2"
    local memory_usage="$3"
    
    # Score baseado em duração (menor é melhor)
    local duration_score=100
    if [[ $duration -gt 30000 ]]; then
        duration_score=50
    elif [[ $duration -gt 15000 ]]; then
        duration_score=75
    elif [[ $duration -gt 5000 ]]; then
        duration_score=90
    fi
    
    # Score baseado em uso de recursos (menor é melhor)
    local resource_score=100
    local avg_resource_usage
    avg_resource_usage=$(echo "scale=2; ($cpu_usage + $memory_usage) / 2" | bc 2>/dev/null || echo "0")
    
    if [[ $(echo "$avg_resource_usage > 50" | bc 2>/dev/null || echo "0") -eq 1 ]]; then
        resource_score=50
    elif [[ $(echo "$avg_resource_usage > 25" | bc 2>/dev/null || echo "0") -eq 1 ]]; then
        resource_score=75
    elif [[ $(echo "$avg_resource_usage > 10" | bc 2>/dev/null || echo "0") -eq 1 ]]; then
        resource_score=90
    fi
    
    # Score final (média ponderada)
    local final_score
    final_score=$(echo "scale=0; ($duration_score * 0.6 + $resource_score * 0.4) / 1" | bc 2>/dev/null || echo "100")
    
    echo "$final_score"
}

generate_error_report() {
    local error_message="$1"
    local error_code="$2"
    local layer="$3"
    local timestamp="$4"
    
    local error_file="$DIAGNOSTIC_BASE_DIR/outputs/$timestamp/$layer/error_report.json"
    
    ensure_output_permissions "$error_file" || return 1
    
    cat > "$error_file" << EOF
{
    "error": {
        "message": "$error_message",
        "code": "$error_code",
        "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
        "layer": "$layer"
    },
    "context": {
        "process_id": $PID,
        "hostname": "$(hostname)",
        "user": "$(whoami)"
    },
    "recovery": {
        "suggested_actions": $(generate_error_suggestions "$error_code"),
        "severity": $(determine_error_severity "$error_code")
    }
}
EOF

    log_debug "Generated error report at: $error_file"
    return 0
}

generate_error_suggestions() {
    local error_code="$1"
    
    case "$error_code" in
        "DOCKER_DAEMON_FAILURE")
            echo '["Restart Docker daemon", "Check Docker service status", "Verify Docker permissions"]'
            ;;
        "CONTAINER_FAILURE")
            echo '["Check container logs", "Restart failed containers", "Verify container configuration"]'
            ;;
        "RESOURCE_CRITICAL")
            echo '["Monitor resource usage", "Scale down workloads", "Add more resources"]'
            ;;
        "CONFIGURATION_ERROR")
            echo '["Verify configuration files", "Check file permissions", "Validate JSON syntax"]'
            ;;
        *)
            echo '["Check system logs", "Verify environment setup", "Contact system administrator"]'
            ;;
    esac
}

determine_error_severity() {
    local error_code="$1"
    
    case "$error_code" in
        "DOCKER_DAEMON_FAILURE"|"RESOURCE_CRITICAL")
            echo '"CRITICAL"'
            ;;
        "CONTAINER_FAILURE"|"CONFIGURATION_ERROR")
            echo '"WARNING"'
            ;;
        *)
            echo '"INFO"'
            ;;
    esac
}

#===============================================================================
# UTILITY FUNCTIONS
#===============================================================================

get_layer_output_path() {
    local layer="$1"
    local timestamp="$2"
    echo "$DIAGNOSTIC_BASE_DIR/outputs/$timestamp/$layer"
}

list_recent_outputs() {
    local count="${1:-5}"
    find "$DIAGNOSTIC_BASE_DIR/outputs" -mindepth 2 -maxdepth 2 -type d | \
        sort -r | head -n "$count" | while read -r dir; do
        echo "$(basename "$(dirname "$dir")")/$(basename "$dir")"
    done
}

get_output_statistics() {
    local timestamp="$1"
    local report_dir="$DIAGNOSTIC_BASE_DIR/outputs/$timestamp"
    
    local total_files=0
    local total_size=0
    
    if [[ -d "$report_dir" ]]; then
        total_files=$(find "$report_dir" -type f | wc -l)
        total_size=$(du -sb "$report_dir" 2>/dev/null | cut -f1 || echo "0")
    fi
    
    cat << EOF
{
    "timestamp": "$timestamp",
    "total_files": $total_files,
    "total_size_bytes": $total_size,
    "layers_present": $(count_layers "$report_dir")
}
EOF
}

count_layers() {
    local report_dir="$1"
    local layer_count=0
    
    if [[ -d "$report_dir" ]]; then
        layer_count=$(find "$report_dir" -mindepth 1 -maxdepth 1 -type d | wc -l)
    fi
    
    echo "$layer_count"
}

#===============================================================================
# CLEANUP
#===============================================================================

cleanup_old_outputs() {
    local days="${1:-7}"

    # Remove diretórios mais antigos que X dias
    find "$DIAGNOSTIC_BASE_DIR/outputs" -mindepth 1 -maxdepth 1 -type d -mtime +"$days" -exec rm -rf {} + 2>/dev/null || {
        log_warning "Failed to cleanup old outputs, attempting with sudo"
        sudo find "$DIAGNOSTIC_BASE_DIR/outputs" -mindepth 1 -maxdepth 1 -type d -mtime +"$days" -exec rm -rf {} + 2>/dev/null
    }

    log_debug "Cleaned up diagnostic outputs older than $days days"
}

cleanup_cache_files() {
    local max_age_hours="${1:-24}"
    
    # Remove arquivos de cache antigos
    find "$DIAGNOSTIC_BASE_DIR/outputs" -name ".cache" -type d -exec find {} -type f -mmin +$((max_age_hours * 60)) -delete \; 2>/dev/null
    
    log_debug "Cleaned up cache files older than $max_age_hours hours"
}

#===============================================================================
# EXPORT FUNCTIONS
#===============================================================================

export DIAGNOSTIC_BASE_DIR OUTPUT_DIR LAYER_NAME TIMESTAMP LOGS_DIR
export -f init_output_handler get_output_dir get_logs_dir ensure_output_permissions
export -f generate_summary_md generate_results_json copy_detailed_log
export -f generate_consolidated_report generate_performance_metrics generate_error_report
export -f get_layer_output_path list_recent_outputs get_output_statistics
export -f cleanup_old_outputs cleanup_cache_files
